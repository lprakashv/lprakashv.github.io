<!doctype html><html><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>Akka Streams in Java Spring Boot! - LALIT's TECH BLOG</title>
<link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#da532c"><meta name=theme-color content="#ffffff"><meta name=viewport content="width=device-width,initial-scale=1"><script async src="https://www.googletagmanager.com/gtag/js?id=G-DNE09NG226"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-DNE09NG226")</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3468549466738898" crossorigin=anonymous></script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3468549466738898" crossorigin=anonymous></script><meta name=description content="Streaming data from a Source to Sink is a very trivial task in today’s data processing and data pipelining systems. Ergo, there are many streaming solutions out there like: Kafka Stream, Spark Streaming, Apache Flink etc.
All of them in one way or another either need an infrastructure to be setup to be able to fully take advantage of them (e.g., HDFS, Spark cluster, Kafka streaming setup etc.) or we need some kind of orchestration among the streaming jobs (e."><meta property="og:image" content><meta property="og:title" content="Akka Streams in Java Spring Boot!"><meta property="og:description" content="Streaming data from a Source to Sink is a very trivial task in today’s data processing and data pipelining systems. Ergo, there are many streaming solutions out there like: Kafka Stream, Spark Streaming, Apache Flink etc.
All of them in one way or another either need an infrastructure to be setup to be able to fully take advantage of them (e.g., HDFS, Spark cluster, Kafka streaming setup etc.) or we need some kind of orchestration among the streaming jobs (e."><meta property="og:type" content="article"><meta property="og:url" content="https://www.lprakashv.com/posts/2020-04-12_akka-streams-in-java-spring-boot/"><meta property="og:image" content="https://www.lprakashv.com/posts/2020-04-12_akka-streams-in-java-spring-boot/images/1.png"><meta property="og:image" content="https://www.lprakashv.com/posts/2020-04-12_akka-streams-in-java-spring-boot/images/2.png"><meta property="og:image" content="https://www.lprakashv.com/posts/2020-04-12_akka-streams-in-java-spring-boot/images/3.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-04-12T10:45:58+00:00"><meta property="article:modified_time" content="2022-08-13T01:14:53+05:30"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://www.lprakashv.com/posts/2020-04-12_akka-streams-in-java-spring-boot/images/1.png"><meta name=twitter:title content="Akka Streams in Java Spring Boot!"><meta name=twitter:description content="Streaming data from a Source to Sink is a very trivial task in today’s data processing and data pipelining systems. Ergo, there are many streaming solutions out there like: Kafka Stream, Spark Streaming, Apache Flink etc.
All of them in one way or another either need an infrastructure to be setup to be able to fully take advantage of them (e.g., HDFS, Spark cluster, Kafka streaming setup etc.) or we need some kind of orchestration among the streaming jobs (e."><script src=https://www.lprakashv.com/js/feather.min.js></script><link href=https://www.lprakashv.com/css/fonts.b685ac6f654695232de7b82a9143a46f9e049c8e3af3a21d9737b01f4be211d1.css rel=stylesheet><link rel=stylesheet type=text/css media=screen href=https://www.lprakashv.com/css/main.42a94afe1d883ff4fcef4d850a21c8e0c6903e7b33798d5ca18916cbd645a78a.css></head><body><div class=content><header><div class=main><div style=display:flex;flex-direction:row><img src=../../Lalit-new-logo-3.png style=border-color:#fff;border-radius:15px;width:150px><div style=margin:auto><a href=https://www.lprakashv.com/ style=font-size:2vh;font-weight:700>LALIT's TECH BLOG</a></div></div></div><nav><a href=../../>Home</a>
<a href=../../posts>All posts</a>
<a href=../../about>About</a>
<a href=../../tags>Tags</a></nav></header><main><article><div class=title><h1 class=title>Akka Streams in Java Spring Boot!</h1><div class=meta>Posted on Apr 12, 2020</div></div><section class=body><p><img src=../../posts/2020-04-12_akka-streams-in-java-spring-boot/images/1.png#layoutTextWidth alt=image></p><p>Streaming data from a Source to Sink is a very trivial task in today’s data processing and data pipelining systems. Ergo, there are many streaming solutions out there like: Kafka Stream, Spark Streaming, Apache Flink etc.</p><p>All of them in one way or another either need an infrastructure to be setup to be able to fully take advantage of them (e.g., HDFS, Spark cluster, Kafka streaming setup etc.) or we need some kind of orchestration among the streaming jobs (e.g., Apache Airflow).</p><h3 id=akka-streams>Akka Streams</h3><p>Akka streams stands out in this battle and have this advantage of being totally application driven. Akka stream is build on top of the Akka’s celebrated Actor model (which in fact is inspired from Erlang’s actor model). Hence, Akka streams can leverage its battle tested <a href=https://www.lightbend.com/blog/why-do-we-need-a-reactive-manifesto>resiliency, elastic, event-driven and responsive</a> (see <a href=https://www.reactivemanifesto.org/>reactive manifesto</a>) capabilities.</p><p><strong>Problems with Akka:</strong></p><ol><li>Java developer community has been staying away from the “made-for and built-on scala” Akka platform.</li><li>Not much documentation and support for the most popular Java framework, “Spring”.</li></ol><p>I’m here to tell you otherwise! Inspite of lack of resources available on the internet, we can in-fact do akka-streams in Java and do it with ease.</p><p>In this post we will build an Akka stream application <strong>in Java</strong> and with <strong>Spring Boot!</strong> And we will analyse the out of the box benefits we can get using Akka streams. So, let’s ge started…</p><h3 id=problem-statement>Problem Statement</h3><p>We need a simple realtime stream which consumes all the updates published on a Kafka topic and persists the events in a SQL server database after parsing. And we only want to commit the Kafka offset after the record has been inserted into the database.</p><p><img src=../../posts/2020-04-12_akka-streams-in-java-spring-boot/images/2.png#layoutTextWidth alt=image>
<strong>Lets start a fresh Spring boot project from Spring Initialzr.</strong></p><p><a href=https://start.spring.io/>Spring Initializr</a></p><p>We will make the project organised like the tree below which is a pretty standard maven directory structure (since we have chosen to use maven here). You could go with gradle also if you like.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-txt data-lang=txt><span style=display:flex><span>.
</span></span><span style=display:flex><span>├── pom.xml
</span></span><span style=display:flex><span>└── src
</span></span><span style=display:flex><span>    ├── main
</span></span><span style=display:flex><span>    │   ├── java
</span></span><span style=display:flex><span>    │   │   └── com
</span></span><span style=display:flex><span>    │   │       └── lprakashv
</span></span><span style=display:flex><span>    │   │           └── springalpakka
</span></span><span style=display:flex><span>    │   │               ├── SpringCommandLineApplication.java
</span></span><span style=display:flex><span>    │   │               ├── configs
</span></span><span style=display:flex><span>    │   │               │   ├── AkkaConfig.java
</span></span><span style=display:flex><span>    │   │               │   └── StreamConfig.java
</span></span><span style=display:flex><span>    │   │               ├── dtos
</span></span><span style=display:flex><span>    │   │               │   └── Event.java
</span></span><span style=display:flex><span>    │   │               ├── services
</span></span><span style=display:flex><span>    │   │               │   └── StreamService.java
</span></span><span style=display:flex><span>    │   │               └── utils
</span></span><span style=display:flex><span>    │   │                   └── StreamUtils.java
</span></span><span style=display:flex><span>    │   └── resources
</span></span><span style=display:flex><span>    │       ├── application.yml
</span></span><span style=display:flex><span>    │       └── stream.conf
</span></span><span style=display:flex><span>    └── test
</span></span><span style=display:flex><span>        └── java
</span></span><span style=display:flex><span>            └── com
</span></span><span style=display:flex><span>                └── lprakashv
</span></span><span style=display:flex><span>                    └── springalpakka
</span></span></code></pre></div><p>Don’t bother about the code files in the tree, we will shortly talk about those.</p><p><strong>Add all the required dependencies:</strong></p><p><img src=../../posts/2020-04-12_akka-streams-in-java-spring-boot/images/3.png#layoutTextWidth alt=image></p><p><strong>Setup Foundational Akka configurations:</strong></p><script src=https://gist.github.com/lprakashv/0928b8c9628407ad6d7f5a0d9a76a165.js></script><p>In every Akka/Akka-Stream application the very basic components needed are the Akka’s <strong>ActorSystem</strong> and <strong>Materializer</strong>. These are needed for a lot of things in this eco-system like, spawning actors, creating stream components, running streams, materializing streams etc.</p><p>In the above code, we made sure:</p><ol><li>We have only one instance beans of both ActorSystem and Materializer throughout our application.</li><li>Will be instantiated only if <strong><em>akka.stream.javadsl.Source</em></strong> is in scope.</li></ol><p><strong>Our Kafka Event DTO to consume:</strong></p><script src=https://gist.github.com/lprakashv/94d2a2eddb36b429ed9a9de4bb36b43c.js></script><p><strong>Let’s write our Source (Kafka)</strong>: We would like to commit the offsets later hence using a <a href=https://doc.akka.io/api/alpakka-kafka/2.0.2/akka/kafka/scaladsl/Consumer$.html#plainSource%5BK,V%5D%28settings:akka.kafka.ConsumerSettings%5BK,V%5D,subscription:akka.kafka.Subscription%29:akka.stream.scaladsl.Source%5Borg.apache.kafka.clients.consumer.ConsumerRecord%5BK,V%5D,akka.kafka.scaladsl.Consumer.Control%5D>committableSource</a>. We will create a Bean out of our committable source to be autowired in our service classes.</p><script src=https://gist.github.com/lprakashv/cc7ad527353aad10ea8c0bdc5c4d0a98.js></script><p><strong>Now let’s write our Flow (Slick):</strong> We could have cerated a Sink if we were to not bother about persist result and commit Kafka offset anyway (using a “<a href=https://doc.akka.io/api/alpakka-kafka/2.0.2/akka/kafka/scaladsl/Consumer$.html#plainSource%5BK,V%5D%28settings:akka.kafka.ConsumerSettings%5BK,V%5D,subscription:akka.kafka.Subscription%29:akka.stream.scaladsl.Source%5Borg.apache.kafka.clients.consumer.ConsumerRecord%5BK,V%5D,akka.kafka.scaladsl.Consumer.Control%5D>plainSource</a>”). We are using flow instead of sink because we want to propagate the committable-offset even after the database stage. We will add the following code in our same config class.</p><script src=https://gist.github.com/lprakashv/865822e16f46cb3cd6274a832a3e9f6f.js></script><p>You might be wondering what is in the <strong><em>stream.conf</em></strong> file and where did that <strong><em>committableMesssageToDTO</em></strong> and <strong><em>insertEventQuery</em></strong> came from?</p><p>Slick needs a configuration to create a session which will execute all our DB queries. This config needs to follow the below structure in a <strong><em>.conf</em></strong> file (which is the standard way to access configs in the typesafe/lightbend world).</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>event-sqlserver {
</span></span><span style=display:flex><span>  profile = &#34;slick.jdbc.SQLServerProfile$&#34;
</span></span><span style=display:flex><span>  db {
</span></span><span style=display:flex><span>    dataSourceClass = &#34;slick.jdbc.DriverDataSource&#34;
</span></span><span style=display:flex><span>    properties {
</span></span><span style=display:flex><span>      driver = &#34;com.microsoft.sqlserver.jdbc.SQLServerDriver&#34;
</span></span><span style=display:flex><span>      url = &#34;your-db-url!&#34;
</span></span><span style=display:flex><span>      user = &#34;your-db-user!&#34;
</span></span><span style=display:flex><span>      password = &#34;your-db-pass&#34;
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>While, the <strong><em>committableMesssageToDTO</em></strong> and <strong><em>insertEventQuery</em></strong> are functions which will convert our CommittableMessage to DTO (our record class) and then to SQL insert query.</p><p>We can write a Utils class with static functions to generate the SQL like:</p><script src=https://gist.github.com/lprakashv/3a60d3145df7fa49c1ea0480a3f6cf4d.js></script><p><strong>Now, let’s piece them together and build a stream:</strong></p><script src=https://gist.github.com/lprakashv/91808cad95f56de6099b5d3d7525a795.js></script><p>This is it! We can now invoke the startKafkaToDatabaseStream() method from anywhere and it will do our job.</p><p>There were a lot of highlighting features there in a single “terse” chain! Let me explain each:</p><ol><li><strong><em>.buffer(size, overflowStrategy)</em></strong>: This will add a fixed-<strong><em>size</em></strong> buffer into our “flow” which will protect the downstream system from a faster upstream source. We can use the strategies for discarding the messages if the size is full: <strong><em>backpressure</em></strong> — will down the consumption, <strong><em>drophead/droptail/dropbuffer</em></strong> — will drop the messages and won’t backpressure and <strong><em>fail</em></strong> — fails the stream on buffer full.</li><li><strong><em>.idleTimeout(duration)</em></strong>: It will throw a <strong><em>java.util.concurrent.TimeoutException</em></strong> on idle timeout duration which can be handled using recover/recoverWith.</li><li><strong><em>.recoverWith(ThrowableClass, fallbackSourceConsumer)</em></strong>: Whenever a ThrowableClass.class exception is intercepted, the original source is replaced by a Source received from the fallbackSourceConsumer.</li><li><strong><em>.throttle(elements, per, maximumburst, mode)</em></strong>: Sends elements downstream with a speed limited to (<strong><em>elements/per</em></strong>), mode=Shaping — makes pauses before emitting to meet the throttle rate, mode=Enforcing — fails with exception when upstream is faster than the throttle rate.</li><li><strong><em>.mapAsync(parallelism, () -&lt; CompletionStage(value))</em></strong>: To process the stage in asynchronous mode with parallelism defined.</li><li><strong><em>CommitterSettings.create(actorSystem)</em></strong>: Creates a default committer settings.</li></ol><p>The DrainingControl can be used as:</p><script src=https://gist.github.com/lprakashv/91808cad95f56de6099b5d3d7525a795.js></script><p>There are a lot of other features of akka stream which were not in scope of this post but still worth to explore. Please checkout <a href=https://doc.akka.io/docs/akka/current/stream/index.html><strong>akka-stream</strong></a> and <a href=https://doc.akka.io/docs/alpakka/current/index.html><strong>alpakka’s</strong></a> documentations.</p><h2 id=conclusion>Conclusion</h2><p>We saw that we could easily integrate Akka streams into our Spring Boot projects and leverage Spring’s dependency injection to manage our Akka/Stream beans easily.</p><p>There are a lot of streaming features like back-pressure and throttling to name a few which would easily take up a lot of developer hours and brains. And yet, we would have missed some corner cases if not tested thoroughly. Those things we got out-of-the-box in akka-stream’s toolkit.</p><p>All in all, Akka-streams along with Alpakka are great tools to have in a data platform stack.</p><p>Thanks for reading!</p></section><div class=post-tags><nav class="nav tags"><ul class=tags><li><a href=../../tags/java>java</a></li><li><a href=../../tags/akka-streams>akka streams</a></li><li><a href=../../tags/spring-boot>spring boot</a></li><li><a href=../../tags/data-pipeline>data pipeline</a></li><li><a href=../../tags/data-ingestion>data ingestion</a></li><li><a href=../../tags/apache-kafka>apache kafka</a></li></ul></nav></div><script id=diffblog-plugin-script async src=https://diff.blog/static/js/diffblog_plugin_v1.js></script><script>document.getElementById("diffblog-plugin-script").addEventListener("load",function(){DiffBlog("hhv3f1602vgc1ljqid62utggmyom9g2ujt9tm6gw74msobue5n")})</script><div id=disqus_thread></div><script>(function(){var e=document,t=e.createElement("script");t.src="https://lprakashv-tech-blog.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t)})()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript></article></main><footer><div style=display:flex><a class=soc href=https://www.linkedin.com/in/lprakashv/ title=Linkedin><i data-feather=linkedin></i></a>
<a class=border></a><a class=soc href=https://github.com/lprakashv title=GitHub><i data-feather=github></i></a>
<a class=border></a><a class=soc href=https://twitter.com/lprakashv/ title=Twitter><i data-feather=twitter></i></a>
<a class=border></a><a class=soc href="https://stackoverflow.com/users/4066802/lprakashv?tab=profile" title=stackoverflow><i data-feather=stackoverflow></i></a>
<a class=border></a></div><div class=footer-info>2024 © Lalit Prakash Vatsal |</div></footer><script>feather.replace()</script></div></body></html>